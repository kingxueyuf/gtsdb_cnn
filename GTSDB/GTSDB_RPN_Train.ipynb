{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster RCNN RPN for GTSDB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is our implementation of a FRCNN RPN for traffic sign detection using the GTSDB dataset\n",
    "\n",
    "Ren, Shaoqing, Kaiming He, Ross Girshick, and Jian Sun. “Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks.” *ArXiv:1506.01497 [Cs]*, June 4, 2015. http://arxiv.org/abs/1506.01497."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.callbacks import ProgbarLogger, ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build base layers (a.k.a. shared layers in the frcnn paper) on the given input layer. The vgg16 network pre-trained on ImageNet was one of the base networks used in the frcnn paper. However, most traffic signs in our datasets are 32x32 in size. Vgg16 has 32x downsample, making it unsuitable for use. The `base` network is a simple network used in our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg(input_layer, trainable=False):\n",
    "    vgg = keras.applications.vgg16.VGG16(include_top=False)\n",
    "    vgg.trainable = trainable\n",
    "    return vgg(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base(input_layer):\n",
    "    return Sequential([\n",
    "        Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation='relu', input_shape=(800,1360,3)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=64, kernel_size=(5,5), padding=\"same\", activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "    ])(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build an RPN on the given base layers with k (no. of anchors at each position, as defined in the paper). Returns a 2-tuple of the 2 output layers: cls and regr, for object/no-object classification and bounding box regression respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rpn(base, k):\n",
    "    x = Conv2D(256, (3, 3), padding='same', activation='relu',\n",
    "               kernel_initializer=keras.initializers.RandomNormal(0.0, 0.01), name='rpn_conv_1')(base)\n",
    "    return(\n",
    "        Conv2D(k,   (1, 1), activation='sigmoid',\n",
    "               kernel_initializer=keras.initializers.RandomNormal(0.0, 0.01), name='rpn_cls')(x),\n",
    "        Conv2D(k*4, (1, 1), activation='linear',\n",
    "               kernel_initializer=keras.initializers.RandomNormal(0.0, 0.01), name='rpn_regr')(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions for working with boxes. These extensively use numpy array manipulation functions to take advantage of the low-level numpy implementation instead of looping in Python-land."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_anchors(rows, cols, sizes, stride):\n",
    "    # Generate 1:1 anchor boxes\n",
    "    # anc_num = len(sizes) [= k in the frcnn paper]\n",
    "    # shape = (rows, cols, anc_num, 4)\n",
    "    return np.expand_dims(np.tile(np.indices((rows,cols)).transpose((1,2,0)) * stride + .5, 2), axis=2).repeat(len(sizes), axis=2)\\\n",
    "        + np.repeat(np.expand_dims(np.array(sizes), axis=1), 4, axis=1) * [-.5, -.5, .5, .5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersect(b1, b2):\n",
    "    # b1.shape = (rows, cols, anc_num, 4)\n",
    "    # b2.shape = (4,)\n",
    "    m = np.minimum(b1,b2)\n",
    "    M = np.maximum(b1,b2)\n",
    "    h = np.maximum(m[...,2] - M[...,0], 0)\n",
    "    w = np.maximum(m[...,3] - M[...,1], 0)\n",
    "    return w*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def union(b1, b2, iarea):\n",
    "    # b1.shape = (rows, cols, anc_num, 4)\n",
    "    # b2.shape = (4,)\n",
    "    a1 = (b1[...,2]-b1[...,0]) * (b1[...,3]-b1[...,1])\n",
    "    a2 = (b2[...,2]-b2[...,0]) * (b2[...,3]-b2[...,1])\n",
    "    return a1 + a2 - iarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iou(b1, b2):\n",
    "    # b1.shape = (rows, cols, anc_num, 4)\n",
    "    # b2.shape = (4,)\n",
    "    iarea = intersect(b1, b2)\n",
    "    uarea = union(b1, b2, iarea)\n",
    "    return iarea/uarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coords2param(ancs, gtbs):\n",
    "    # Convert absolute coords to parametrized params (see frcnn paper)\n",
    "    # ancs.shape = gtbs.shape = (rows, cols, anc_num, 4)\n",
    "    # box = [y1,x1,y2,x2]\n",
    "    \n",
    "    wa = ancs[...,3] - ancs[...,1]\n",
    "    ha = ancs[...,2] - ancs[...,0]\n",
    "    tx = (gtbs[...,1] - ancs[...,1]) / wa\n",
    "    ty = (gtbs[...,1] - ancs[...,1]) / ha\n",
    "    tw = np.log((gtbs[...,3] - gtbs[...,1]) / wa)\n",
    "    th = np.log((gtbs[...,2] - gtbs[...,0]) / ha)\n",
    "    \n",
    "    # shape = (row, cols, anc_num, 4)\n",
    "    return np.stack([tx,ty,tw,th], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def anchors_vs_gt(ancs, gtbs, lo=.3, hi=.7):\n",
    "    # ancs.shape = (rows, cols, anc_num, 4)\n",
    "    # gtbs.shape = (gtb_num, 4)\n",
    "    \n",
    "    # ious.shape = (rows, cols, anc_num, gtb_num)\n",
    "    ious = np.stack([iou(ancs, gtb) for gtb in gtbs], axis=-1)\n",
    "    # best.shape = (gtb_num,)\n",
    "    best = ious.reshape((-1, gtbs.shape[0])).max(axis=0)\n",
    "    \n",
    "    # box_pos.shape = box_neg.shape = (rows, cols, anc_num)\n",
    "    box_pos = np.logical_or(ious.max(axis=-1) >= hi, np.logical_and(ious == best, best > 0).any(axis=-1))\n",
    "    box_neg = ious.max(axis=-1) <= lo\n",
    "    \n",
    "    # hard_pos = anchor boxes with iou >= hi with any gt box\n",
    "    # soft_pos = anchor boxes with highest iou with a gt box\n",
    "    # hard_neg = anchor boxes with iou <= lo with all gt boxes\n",
    "    ## print(\"\\thard_pos = {:d}\".format(np.sum(ious.max(axis=-1) >= hi)))\n",
    "    ## print(\"\\tsoft_pos = {:d}\".format(np.sum(np.logical_and(ious == best, best > 0).any(axis=-1))))\n",
    "    ## print(\"\\thard_neg = {:d}\".format(np.sum(ious.max(axis=-1) <= lo)))\n",
    "    \n",
    "    # best_gt.shape = (rows, cols, anc_num, 4)\n",
    "    best_gt = np.take(gtbs, ious.argmax(axis=-1), axis=0)\n",
    "    \n",
    "    return box_pos, box_neg, coords2param(ancs, best_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_boxes(pos, neg, num=256):\n",
    "    # Only use num boxes, with pos:neg at most 1:1 unless pos < num/2\n",
    "    p_num = pos[pos].shape[0]\n",
    "    n_num = neg[neg].shape[0]\n",
    "    if p_num > num/2:\n",
    "        pos[np.vsplit(np.vstack(np.where(pos))[:,np.random.choice(p_num, p_num-num//2, replace=False)], pos.ndim)] = False\n",
    "        p_num = num//2\n",
    "    if n_num + p_num > num:\n",
    "        neg[np.vsplit(np.vstack(np.where(neg))[:,np.random.choice(n_num, n_num-num+p_num, replace=False)], neg.ndim)] = False\n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss functions as defined in the frcnn paper:  \n",
    "`L({pi}, {ti}) = (1/Ncls) Σ Lcls(pi, pi*) + λ(1/Nreg) Σ pi* Lreg(ti, ti*)`\n",
    "\n",
    "In this implementation we ignore the balancing factor λ and the normalization, which the paper say is okay:  \n",
    "`L({pi}, {ti}) = Σ Lcls(pi, pi*) + Σ pi* Lreg(ti, ti*)`  \n",
    "where `Lcls` is binary log loss  \n",
    "and `Lreg` is robust loss\n",
    "\n",
    "Here, `rpn_cls_loss` is `Σ Lcls(pi, pi*)`  \n",
    "and `rpn_regr_loss` is `Σ pi* Lreg(ti, ti*)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rpn_regr_loss(num_ancs):\n",
    "    def loss(ytrue, ypred, ptrue):\n",
    "        # ytrue.shape = (rows, cols, num_ancs * 4)\n",
    "        # ypred.shape = (rows, cols, num_ancs * 4)\n",
    "        # ptrue.shape = (rows, cols, num_ancs * 4)\n",
    "        # ancs.shape  = (rows, cols, num_ancs * 4)\n",
    "        \n",
    "        dy = ytrue - ypred\n",
    "        sw = K.cast(K.less(K.abs(dy), 1), dtype=K.floatx())\n",
    "        r1 = sw*dy*dy*.5\n",
    "        r2 = (1-sw)*(K.abs(dy)-.5)\n",
    "        return K.sum((r1+r2) * ptrue)\n",
    "    return lambda ytrue, ypred: \\\n",
    "        loss(ytrue[...,4*num_ancs:],\n",
    "             ypred,\n",
    "             ytrue[...,:4*num_ancs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rpn_cls_loss(num_ancs):\n",
    "    def loss(postrue, negtrue, ppred):\n",
    "        # Add epsilon = 1e-4 to prevent log(0)\n",
    "        return K.sum(- postrue * K.log(1e-4 + ppred)\n",
    "                     - negtrue * K.log(1e-4 + 1-ppred))\n",
    "    return lambda ptrue, ppred: \\\n",
    "        loss(ptrue[...,:num_ancs], ptrue[...,num_ancs:], ppred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generator. Reads from the GTSDB training set. Generate a mini-batch (one image) each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def datagen(start, stop, ancs=None, shuffle=True):\n",
    "    \"\"\"Generator for GTSDB dataset\n",
    "        Args:\n",
    "            start, stop = range of images to use\n",
    "            ancs = anchor boxes to use. Use get_anchors() to generate these.\n",
    "                Dimensions should be (imageheight/basenet_stride, imagewidht/basenet_stride, k, basenet_stride)\n",
    "                Defaults to be get_anchors(200, 340, [16,24,32], 4)\n",
    "            shuffle = whether to shuffle the data\n",
    "    \"\"\"\n",
    "    if ancs is None:\n",
    "        ancs = get_anchors(200, 340, [16,24,32], 4)\n",
    "    csv = np.loadtxt('../dataset/PNG_train/gt.txt', delimiter=',', converters = {0: lambda x:x[:-4]}, dtype=np.int32)\n",
    "    \n",
    "    idx = np.arange(start, stop)\n",
    "    \n",
    "    for i in idx:\n",
    "        temp = csv[csv[:,0] == i]\n",
    "        temp = temp[:,[2,1,4,3]]\n",
    "        # temp.shape = (gtb_num, 4)\n",
    "        \n",
    "        ## print(\"fname = ../dataset/PNG_train/{:05d}.png\".format(i))\n",
    "        pos, neg, gtbs = anchors_vs_gt(ancs, temp)\n",
    "        gtbs = gtbs.reshape((gtbs.shape[0], gtbs.shape[1], -1))\n",
    "        # pos.shape = neg.shape = (rows, cols, anc_num)\n",
    "        # gtbs.shape = (row, cols, anc_num * 4)\n",
    "        pos, neg = filter_boxes(pos, neg)\n",
    "        \n",
    "        # x_img.shape  = (1, imgh, imgw, imgchannels)\n",
    "        # y_cls.shape  = (row, cols, anc_num * 2)\n",
    "        # y_regr.shape = (row, cols, anc_num * 8)\n",
    "        x_img  = np.expand_dims(imread('../dataset/PNG_train/{:05d}.png'.format(i)), 0)\n",
    "        y_cls  = np.expand_dims(np.concatenate((pos, neg), axis=-1).astype(np.int32), 0)\n",
    "        y_regr = np.expand_dims(np.concatenate((pos.repeat(4, axis=-1), gtbs), axis=-1), 0)\n",
    "        \n",
    "        yield (x_img, [y_cls, y_regr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for models in the checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "temp = [re.compile('gtsdb_rpn-(\\d+)\\.hdf5').match(fn) for fn in os.listdir('models/gtsdb_rpn/')]\n",
    "temp = [int(m.group(1)) for m in temp if m is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If models are found, load the latest model.  \n",
    "Otherwise build new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(temp) == 0:\n",
    "    inp = Input(shape=(800,1360,3))\n",
    "    # Can use vgg(inp) instead of base(inp)\n",
    "    model = Model(inputs=inp, outputs=rpn(base(inp), 3))\n",
    "else:\n",
    "    model = keras.models.load_model('models/gtsdb_rpn/gtsdb_rpn-{:d}.hdf5'.format(max(temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss={'rpn_cls': rpn_cls_loss(3), 'rpn_regr': rpn_regr_loss(3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-call train function. Generates checkpoints and tensorboard logs. Early stopping on validation error plateau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    datagen(0, 600, shuffle=True),\n",
    "    steps_per_epoch = 600,\n",
    "    epochs = 100,\n",
    "    validation_data = datagen(600, 900),\n",
    "    validation_steps = 300,\n",
    "    verbose = 1,\n",
    "    callbacks = [\n",
    "        ProgbarLogger(count_mode='steps'),\n",
    "        ModelCheckpoint('models/gtsdb_rpn/gtsdb_rpn-{epoch}.hdf5', verbose=1, save_best_only = True),\n",
    "        TensorBoard(log_dir='tblogs/gtsdb_rpn/', write_graph=True, write_grads=True, write_images=True),\n",
    "        EarlyStopping(patience=5, verbose=1),\n",
    "    ],)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
